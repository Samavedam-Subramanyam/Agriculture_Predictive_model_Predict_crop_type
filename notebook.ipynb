# All required libraries are imported here for you.
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics

# Load the dataset
# crops = pd.read_csv("soil_measures.csv")  # This line is not needed as the dataframe is already defined in the environment

# Correcting the code
# Creating a variable crop
crop_only = crops.loc[crops["crop"].notnull()]
no_crop = crops.loc[crops["crop"].isnull()]

# Splitting the data
X = crops[["N", "P", "K", "ph"]]
y = crops["crop"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)

# Evaluating performance
# Dictionary to store each feature's predictive performance
dic = {}

for feature in ["N", "P", "K", "ph"]:
    logreg = LogisticRegression()
    logreg.fit(X_train[[feature]], y_train)
    y_pred = logreg.predict(X_test[[feature]])
    feature_performance = metrics.f1_score(y_test, y_pred, average='weighted')
    dic[feature] = feature_performance
    print(f"F1-score for {feature}: {feature_performance}")

# Finding the best predictive feature
best_predictive_feature = {max(dic, key=dic.get): dic[max(dic, key=dic.get)]}
print(best_predictive_feature)
